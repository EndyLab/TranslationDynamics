{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from analysis_utils import *\n",
    "%load_ext autoreload\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "ptRNA = pd.read_excel('tRNAValues.xlsx',header=None)\n",
    "gr04_ptRNA=ptRNA[0]\n",
    "gr07_ptRNA=ptRNA[1]\n",
    "gr107_ptRNA=ptRNA[2]\n",
    "gr16_ptRNA=ptRNA[3]\n",
    "gr25_ptRNA=ptRNA[4]\n",
    "\n",
    "pCodon = pd.read_excel('codonValues.xlsx',header=None)\n",
    "gr04_pCodon = pCodon[0]\n",
    "gr07_pCodon = pCodon[1]\n",
    "gr107_pCodon = pCodon[2]\n",
    "gr16_pCodon = pCodon[3]\n",
    "gr25_pCodon = pCodon[4]\n",
    "\n",
    "rxndiff=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeBiasedElongationLatency(biasVal=1):\n",
    "    sim_time_all = list()\n",
    "    sim_time_std_all = list()\n",
    "    rib_gr = [4,8,9,9,8,7]\n",
    "    ptRNA = [gr07_ptRNA,gr107_ptRNA,gr16_ptRNA,gr16_ptRNA,gr25_ptRNA,gr25_ptRNA]\n",
    "    pCodon =  [gr07_pCodon,gr107_pCodon,gr16_pCodon,gr16_pCodon,gr25_pCodon,gr25_pCodon]\n",
    "\n",
    "    for i,num_rib in enumerate(rib_gr):\n",
    "        weight = cognateDistrib(ptRNA[i],pCodon[i])\n",
    "        sim_time_gr = list()\n",
    "        sim_time_gr_var=list()\n",
    "        rxn_count_gr = list()\n",
    "\n",
    "        num_tRNA=42\n",
    "        for num_tRNA in np.arange(1,42):\n",
    "            sim_times=list()\n",
    "            rxn_count = list()\n",
    "            N=1000\n",
    "            for i in range(N):\n",
    "                rxn = eventbased_sim(rib_num=num_rib,tRNA_cog=num_tRNA,repeatAllowed=True,bias=biasVal)\n",
    "                sim_times.append(rxn[0])\n",
    "                rxn_count.append(rxn[1])\n",
    "            sim_time_gr.append(np.average(sim_times))\n",
    "            rxn_count_gr.append(np.average(rxn_count))\n",
    "            sim_time_gr_var.append(np.std(sim_times)**2)\n",
    "\n",
    "        #print(np.sum(sim_time_gr*weight[1:len(sim_time_gr)+1]))\n",
    "        sim_time_all.append(np.sum(sim_time_gr*weight[1:len(sim_time_gr)+1]))\n",
    "        sim_time_std_all.append(np.sqrt(np.sum((sim_time_gr_var)*weight[1:len(sim_time_gr)+1]))/np.sqrt(num_tRNA*N))\n",
    "    return(sim_time_all, sim_time_std_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Bias:  1.0 \n",
      " [37.63759268889624, 38.320504226913734, 36.98292889637495, 37.44690694617251, 35.67909294797215, 36.246404486001616] [0.2555239736453694, 0.2511613758593155, 0.25174408096348694, 0.24588885030176924, 0.23314029750878662, 0.2487483465026793]\n",
      "\n",
      "\n",
      "Bias:  1.5 \n",
      " [24.36417456610702, 24.276044204058948, 22.843728802151887, 24.133837091388116, 23.753116633877294, 23.793360290491055] [0.16442824994385244, 0.15606078286048414, 0.1533695447851116, 0.15975970166420855, 0.1550998337516166, 0.15732410120635335]\n",
      "\n",
      "\n",
      "Bias:  2.0 \n",
      " [18.55239448485358, 17.496836493441414, 16.84370299474137, 16.759298691363888, 17.70858002323581, 17.710808682632013] [0.12936723917746792, 0.11534063087534994, 0.10993900113543817, 0.1109532926988609, 0.11801505838157665, 0.11862782576583489]\n",
      "\n",
      "\n",
      "Bias:  2.5 \n",
      " [14.726554552292944, 13.755676963412451, 13.723748117819614, 13.718034049079872, 13.622079591530762, 13.808922636925468] [0.0959399489769176, 0.08892800620076124, 0.09080324711335722, 0.08791886105557849, 0.08625266894070813, 0.09409250574585122]\n",
      "\n",
      "\n",
      "Bias:  3.0 \n",
      " [12.507335286495065, 11.825845142074593, 11.36531580711633, 11.604404601017121, 11.6937809044033, 11.377093499280475] [0.08419987522870817, 0.07774713619266783, 0.07477269302864148, 0.07738179613670584, 0.07477733643709601, 0.0748549513752791]\n",
      "\n",
      "\n",
      "Bias:  3.5 \n",
      " [10.494685832200748, 10.655810239014205, 10.068889401252033, 9.6416306269696, 10.175746448555467, 10.287873068848432] [0.06956333460486032, 0.07294519175913088, 0.06801218363723968, 0.06264261001519605, 0.0660045918670191, 0.06886093496401398]\n",
      "\n",
      "\n",
      "Bias:  4.0 \n",
      " [10.053096675717601, 9.139520572436039, 8.971653361053075, 9.269546828498404, 8.928095221372287, 9.428872246748016] [0.06658923489856955, 0.06005403884068845, 0.05758838535945251, 0.06226160746956613, 0.05951703401703227, 0.06429319201305342]\n",
      "\n",
      "\n",
      "Bias:  4.5 \n",
      " [8.645388919594104, 8.072693931963862, 7.673151105009239, 7.984973466230896, 7.933687939187541, 8.1177238205802] [0.05892060529412611, 0.05244284040010041, 0.04977457423878957, 0.0549357231262081, 0.05171076206781925, 0.05313697023969834]\n",
      "\n",
      "\n",
      "Bias:  5.0 \n",
      " [7.815995066582833, 7.176962798787865, 6.8486319994806415, 7.492726716621453, 7.252594948776251, 7.147565703185287] [0.05552445350507035, 0.04691324871387732, 0.0445666510461478, 0.04835761880799801, 0.04686705548983446, 0.04687472131051723]\n",
      "\n",
      "\n",
      "Bias:  5.5 \n",
      " [7.210568147868011, 6.444902982200133, 6.501207390354725, 6.649574866701018, 6.6705442004789, 6.697038887053068] [0.04753995422991069, 0.0424247583131219, 0.04337717607070733, 0.04192532267293138, 0.04239154160493212, 0.0424103865790822]\n",
      "\n",
      "\n",
      "Bias:  6.0 \n",
      " [6.635098157757119, 6.110056725903721, 5.9620427831631595, 6.233138704088574, 6.040144018684561, 6.4325838748010105] [0.043635823746280625, 0.0400687891800276, 0.040108137082732455, 0.04291420431952027, 0.03990399898414277, 0.04268591938086254]\n",
      "\n",
      "\n",
      "Bias:  6.5 \n",
      " [6.358669296404226, 5.920766868721252, 5.679977965513653, 5.639000286839471, 5.541560035415888, 5.866040443825189] [0.04220682869183174, 0.04046457239484636, 0.037376633807882136, 0.03687431703658105, 0.036487959429760845, 0.038959335464522474]\n",
      "\n",
      "\n",
      "Bias:  7.0 \n",
      " [5.7968041601293585, 5.688071153557065, 5.278238360413784, 5.5782333574473135, 5.536629516024693, 5.463247291838806] [0.03859204845856918, 0.03808239186713387, 0.03564524549262488, 0.03625026558183574, 0.03608521321601643, 0.03480764320797733]\n",
      "\n",
      "\n",
      "Bias:  7.5 \n",
      " [5.533776769980263, 5.310824502838144, 4.922936057428208, 5.066862307088037, 5.221626749167816, 5.338499141601269] [0.03766711780157883, 0.03534195771636605, 0.032988342086041136, 0.03432369721833313, 0.03542774921361338, 0.03581582095474088]\n",
      "\n",
      "\n",
      "Bias:  8.0 \n",
      " [5.147844843427189, 5.156289005258585, 4.89627355226127, 4.877686587841887, 4.791251070401338, 5.225313512681497] [0.0347098671171768, 0.03409768497221894, 0.031584894154714056, 0.03158940504495903, 0.03254465390009412, 0.034731563400077346]\n",
      "\n",
      "\n",
      "Bias:  8.5 \n",
      " [4.968336952979381, 4.750445069750145, 4.560295497552055, 4.587974786485326, 4.671643216848647, 4.80351357724125] [0.033499490115424316, 0.03163184467688993, 0.0296362304567313, 0.031128183706792302, 0.03062246309000212, 0.03135884722490283]\n",
      "\n",
      "\n",
      "Bias:  9.0 \n",
      " [4.577589762637819, 4.4823653884173815, 4.312979420205966, 4.471046988292652, 4.479309216719983, 4.663692722520838] [0.029971664215179838, 0.028194466403715163, 0.02940517048813161, 0.029479218263076257, 0.0294844965045183, 0.03206764646967693]\n",
      "\n",
      "\n",
      "Bias:  9.5 \n",
      " [4.38786892199944, 4.234905556854755, 4.185535878071977, 4.166127641765912, 4.242940040930146, 4.261499584101478] [0.030106018088103467, 0.027730296914744334, 0.0272406881439049, 0.027556102686923132, 0.028403306651088537, 0.028290668076828878]\n"
     ]
    }
   ],
   "source": [
    "elongLatencyList = list()\n",
    "elongLatency_STDlist = list()\n",
    "bias = np.arange(1,10,0.5)\n",
    "\n",
    "for biasVal in bias:\n",
    "    elongLatency, elongLatency_STD = computeBiasedElongationLatency(biasVal)\n",
    "    elongLatencyList.append(elongLatency)\n",
    "    elongLatency_STDlist.append(elongLatency_STD)\n",
    "    print(\"\\n\\nBias: \", biasVal, \"\\n\", elongLatency, elongLatency_STD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
